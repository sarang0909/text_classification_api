{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from newsapi import NewsApiClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key=<KEY>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "total_articles = list()\n",
    " \n",
    "total_pages = 1\n",
    "while total_pages<=5:\n",
    "    all_data = newsapi.get_everything( q='Tesla',\n",
    "                                      sources='reuters',\n",
    "                                      from_param='2022-08-25',\n",
    "                                      to='2022-09-20',\n",
    "                                      language='en',\n",
    "                                      page = total_pages                        \n",
    "                                       )\n",
    "     \n",
    "    df2 = pd.DataFrame.from_records(all_data['articles'])\n",
    "    df1 = pd.concat([df1,df2])\n",
    "   \n",
    "    total_pages += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   source       80 non-null     object\n",
      " 1   author       6 non-null      object\n",
      " 2   title        80 non-null     object\n",
      " 3   description  80 non-null     object\n",
      " 4   url          80 non-null     object\n",
      " 5   urlToImage   80 non-null     object\n",
      " 6   publishedAt  80 non-null     object\n",
      " 7   content      80 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 5.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "    except:\n",
    "        return \"\"\n",
    "    return article.text\n",
    "\n",
    "df1['article_text'] = df1.apply (lambda row: get_article_text(row['url']), axis=1)\n",
    "df1.to_csv('../../data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "from utility import nlp_text_cleaner\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    80 non-null     int64 \n",
      " 1   source        80 non-null     object\n",
      " 2   author        6 non-null      object\n",
      " 3   title         80 non-null     object\n",
      " 4   description   80 non-null     object\n",
      " 5   url           80 non-null     object\n",
      " 6   urlToImage    80 non-null     object\n",
      " 7   publishedAt   80 non-null     object\n",
      " 8   content       80 non-null     object\n",
      " 9   article_text  79 non-null     string\n",
      "dtypes: int64(1), object(8), string(1)\n",
      "memory usage: 6.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79 entries, 0 to 79\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    79 non-null     int64 \n",
      " 1   source        79 non-null     object\n",
      " 2   author        5 non-null      object\n",
      " 3   title         79 non-null     object\n",
      " 4   description   79 non-null     object\n",
      " 5   url           79 non-null     object\n",
      " 6   urlToImage    79 non-null     object\n",
      " 7   publishedAt   79 non-null     object\n",
      " 8   content       79 non-null     object\n",
      " 9   article_text  79 non-null     string\n",
      "dtypes: int64(1), object(8), string(1)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../../data/raw_data.csv',dtype={'article_text':'string'})\n",
    "raw_data.info()\n",
    "raw_data = raw_data.dropna(subset=['article_text'])\n",
    "raw_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = []\n",
    "for paragraph in raw_data['article_text']:\n",
    "    sentences = sentences + nlp_text_cleaner.clean_paragraph_to_sentences(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_clean_data = pd.DataFrame (sentences, columns = ['sentence'])\n",
    "sentences_clean_data.to_csv('../../data/sentences_clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\metes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    80 non-null     int64 \n",
      " 1   source        80 non-null     object\n",
      " 2   author        6 non-null      object\n",
      " 3   title         80 non-null     object\n",
      " 4   description   80 non-null     object\n",
      " 5   url           80 non-null     object\n",
      " 6   urlToImage    80 non-null     object\n",
      " 7   publishedAt   80 non-null     object\n",
      " 8   content       80 non-null     object\n",
      " 9   article_text  79 non-null     string\n",
      "dtypes: int64(1), object(8), string(1)\n",
      "memory usage: 6.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79 entries, 0 to 79\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    79 non-null     int64 \n",
      " 1   source        79 non-null     object\n",
      " 2   author        5 non-null      object\n",
      " 3   title         79 non-null     object\n",
      " 4   description   79 non-null     object\n",
      " 5   url           79 non-null     object\n",
      " 6   urlToImage    79 non-null     object\n",
      " 7   publishedAt   79 non-null     object\n",
      " 8   content       79 non-null     object\n",
      " 9   article_text  79 non-null     string\n",
      "dtypes: int64(1), object(8), string(1)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../../data/raw_data.csv',dtype={'article_text':'string'})\n",
    "raw_data.info()\n",
    "raw_data = raw_data.dropna(subset=['article_text'])\n",
    "raw_data.info()\n",
    "paragraph_clean_data = pd.DataFrame()\n",
    "paragraph_clean_data['paragraph'] = raw_data[\"article_text\"].apply(nlp_text_cleaner.clean_paragraph)\n",
    "paragraph_clean_data.to_csv('../../data/paragraph_clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sentiment_analysis_api')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efb0b56b023af68850f7e8be89ed314f1b3967a8a73a058021998b0dc2fde313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
